{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSR 20 - Backprop course\n",
    "\n",
    "## 1. perceptron and the delta rule\n",
    "\n",
    "#### Perceptron training:\n",
    "1. Initialize weights vector with small random numbers\n",
    "2. Repeat until convergence:\n",
    "    Loop over feature vector (ùë•j) and labels (li) in training set D.\n",
    "    Take ùë• and pass it through the perceptron, calculating the output values: \n",
    "    $$ y_{j}=w(t)\\cdot x_{j}=∆í(w(t))_{x_{j}}$$\n",
    "    Update weights: \n",
    "    $$ w_{i}(t+1)=w_{i}(t)+ùõº(l_{j}-y_{j})x_{j}$$  \n",
    "    for all 0 <= i < n\n",
    "3. Terminate criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    # N is the length of are input feature \n",
    "    # alpha learning rate\n",
    "    def __init__(self, N, alpha=0.1):\n",
    "        # initialize the weight matrix and store the learning rate\n",
    "        self.W = np.random.randn(N ) / np.sqrt(N)\n",
    "        self.N = N\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def step(self, x):\n",
    "        # apply a step activation function\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "    def fit(self, X, y, epochs=10, addBias=True):\n",
    "        # insert a column of 1's as the last entry in the feature\n",
    "        # matrix -- this little trick allows us to treat the bias\n",
    "        # as a trainable parameter within the weight matrix\n",
    "        if addBias:\n",
    "            print(addBias)\n",
    "            X = np.c_[X, np.ones((X.shape[0]))]\n",
    "            self.W = np.random.randn(self.N+1) / np.sqrt(self.N)\n",
    "            \n",
    "        # loop over the desired number of epochs\n",
    "        for epoch in np.arange(0, epochs):\n",
    "            # loop over each individual data point\n",
    "                for (x, target) in zip(X, y):\n",
    "                # take the dot product between the input features\n",
    "                # and the weight matrix, then pass this value\n",
    "                # through the step function to obtain the prediction\n",
    "                    p = self.step(np.dot(x, self.W))\n",
    "                    # perform weight update if prediction\n",
    "                    # does not match trget\n",
    "                    if p != target:\n",
    "                        # calculate delta\n",
    "                        delta = p - target\n",
    "                        # update the weight matrix\n",
    "                        self.W += -self.alpha * delta * x \n",
    "    \n",
    "    def predict(self, X, addBias=True):\n",
    "        # ensure our input is a matrix\n",
    "        X = np.atleast_2d(X)\n",
    "        # check to see if the bias column should be added\n",
    "        if addBias:\n",
    "            # insert a column of 1's as the last entry in the feature\n",
    "            # matrix (bias)\n",
    "            X = np.c_[X, np.ones((X.shape[0]))]\n",
    "            # take the dot product between the input features and the\n",
    "            # weight matrix, then pass the value through the step\n",
    "            # function\n",
    "        return self.step(np.dot(X, self.W))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the OR dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "# define our perceptron and train it\n",
    "print(\"training perceptron...\")\n",
    "p = Perceptron(X.shape[1], alpha=0.1)\n",
    "p.fit(X, y, epochs=20,addBias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that our perceptron is trained we can evaluate it\n",
    "print(\"testing perceptron...\")\n",
    "\n",
    "# now that our network is trained, loop over the data points\n",
    "for (x, target) in zip(X, y):\n",
    "    # make a prediction on the data point and display the result\n",
    "    # to our console\n",
    "    pred = p.predict(x,addBias=False)\n",
    "    print(\"data={}, true_label={}, pred={}\".format(\n",
    "        x, target[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the weights during training and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the Perceptron class such that you save the weights during training and return them then plot them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat now with bias (addBias=True), what happend to the weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change the learning rate how are the weights changing now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Repeat all steps for an AND data set\n",
    "### 2. Repeat all steps for a XOR data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the AND dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "### ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the XOR dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "### ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange (0,100,1)\n",
    "noise = np.random.normal(loc=0.0, scale=5, size=100)\n",
    "y = 70 + 1.2*X + noise\n",
    "\n",
    "# normalization of inputs and lables \n",
    "y=y/np.max(X)\n",
    "X=X/np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How should you change the activation function to fit a regression problem???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the perceptron class here for regression\n",
    "\n",
    "class Perceptron:\n",
    "    # N is the length of are input feature \n",
    "    # alpha learning rate\n",
    "    def __init__(self, N, alpha=0.1):\n",
    "        # initialize the weight matrix and store the learning rate\n",
    "        self.W = np.random.randn(N ) / np.sqrt(N)\n",
    "        self.N = N\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def step(self, x):\n",
    "        # apply a linear activation\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "    def fit(self, X, y, epochs=10, addBias=True):\n",
    "        # insert a column of 1's as the last entry in the feature\n",
    "        # matrix -- this little trick allows us to treat the bias\n",
    "        # as a trainable parameter within the weight matrix\n",
    "        if addBias:\n",
    "            print(addBias)\n",
    "            X = np.c_[X, np.ones((X.shape[0]))]\n",
    "            self.W = np.random.randn(self.N+1) / np.sqrt(self.N)\n",
    "            \n",
    "        # loop over the desired number of epochs\n",
    "        w = self.W\n",
    "       \n",
    "        for epoch in np.arange(0, epochs):\n",
    "        # loop over each individual data point\n",
    "            for (x, target) in zip(X, y):\n",
    "            # take the dot product between the input features\n",
    "            # and the weight matrix, then pass this value\n",
    "            # through the step function to obtain the prediction\n",
    "                p = self.step(np.dot(x, self.W))\n",
    "                # perform weight update if prediction\n",
    "                # does not match trget\n",
    "                #if p != target:\n",
    "                    # calculate delta\n",
    "                delta = p - target\n",
    "                    # update the weight matrix\n",
    "                self.W += -self.alpha * delta * x\n",
    "            w = np.append(w,[self.W])\n",
    "                   \n",
    "        return w\n",
    "    \n",
    "    def predict(self, X, addBias=True):\n",
    "        # ensure our input is a matrix\n",
    "        X = np.atleast_2d(X)\n",
    "        # check to see if the bias column should be added\n",
    "        if addBias:\n",
    "            # insert a column of 1's as the last entry in the feature\n",
    "            # matrix (bias)\n",
    "            X = np.c_[X, np.ones((X.shape[0]))]\n",
    "            # take the dot product between the input features and the\n",
    "            # weight matrix, then pass the value through the step\n",
    "            # function\n",
    "        return self.step(np.dot(X, self.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our perceptron and train it\n",
    "\n",
    "C\n",
    "print(\"training perceptron...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT DATA AS ABOVE AND ADD A PLOT OF THE PREDICTION\n",
    "### ENTER YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE WEIGHTS AS A FUNCTION OF TRAINING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  repeat the training without bias (addBias = False) , what happend?\n",
    "### 2.  repeat the training without the normalization of the data, what happend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
